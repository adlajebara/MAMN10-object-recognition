{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5742b243",
   "metadata": {},
   "source": [
    "## Import libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e51c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if image is corrupted \n",
    "\n",
    "from pathlib import Path\n",
    "import imghdr\n",
    "\n",
    "data_dir = \"/datasets/face_dataset_train_images/epi\"\n",
    "image_extensions = [\".jpg\"] \n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    #if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        img_type\n",
    "        #if img_type is None:\n",
    "           # print(f\"{filepath} is not an image\")\n",
    "       # elif img_type not in img_type_accepted_by_tf:\n",
    "          #  print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55a9a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow imports\n",
    "# may differs from version to versions\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c6b9aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "\n",
    "image_folder = os.path.join('datasets', 'face_dataset_train_images')\n",
    "img_height, img_width = 250, 250  # size of images\n",
    "num_classes = 3  # me - not_me - epi\n",
    "\n",
    "# 'face_dataset_train_images' and 'face_dataset_test_images' folders follow next structure:\n",
    "# | - dataset_folder (face_dataset_train_images/face_dataset_test_images)\n",
    "#     | - class_1\n",
    "#         | - img1.jpg\n",
    "#         | - img2.jpg\n",
    "#         | - ...\n",
    "#     | - class_2\n",
    "#         | - img1.jpg\n",
    "#         | - img2.jpg\n",
    "#         | - ...\n",
    "#     | - ...\n",
    "\n",
    "# In my case\n",
    "# | - face_dataset_train_images\n",
    "#     | - me\n",
    "#         | - ...\n",
    "#     | - not_me\n",
    "#         | - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859cfc31",
   "metadata": {},
   "source": [
    "## Look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79149017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    image_folder,\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41838ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epi', 'me', 'not_me']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1434591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get classname of the image\n",
    "def get_classname(class_names, mask):\n",
    "    '''\n",
    "    Returns an element of the array 'class_names' with the index\n",
    "    where the maximum value from the 'mask' array is located.\n",
    "    Used to get classname with categorical labels.\n",
    "\n",
    "    Parameters:\n",
    "        class_names (array-like): Target array\n",
    "        mask (array-like): Mask array, elements must be numbers\n",
    "    Returns:\n",
    "        One of the element from 'class_names'\n",
    "\n",
    "    >>> get_classname(['first', 'second'], [0, 1])\n",
    "    'second'\n",
    "    >>> get_classname(['first', 'second', third], [1, 0, 0])\n",
    "    'first'\n",
    "    '''\n",
    "\n",
    "    assert len(class_names) == len(\n",
    "        mask), \"The arrays must be of the same length\"\n",
    "\n",
    "    return class_names[np.array(mask).argmax(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae936905",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# The square root of the total number of images shown\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sqrt_img\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# grid 'sqrt_img' x 'sqrt_img'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         plt\u001b[38;5;241m.\u001b[39msubplot(sqrt_img, sqrt_img, index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlp/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlp/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlp/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlp/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqrt_img = 2  # images per row / col.\n",
    "# The square root of the total number of images shown\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in dataset.take(3):\n",
    "    for index in range(sqrt_img**2):\n",
    "        # grid 'sqrt_img' x 'sqrt_img'\n",
    "        plt.subplot(sqrt_img, sqrt_img, index + 1)\n",
    "        plt.imshow(images[index] / 255)\n",
    "        class_name = get_classname(class_names, labels[index])\n",
    "        plt.title(\"Class: {}\".format(class_name))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64def32f",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator based on ImageDataGenerator object\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.7, 1),\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    image_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see next augmented image\n",
    "image, label = train_generator.next()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image[0] / 255)  # first image from batch\n",
    "plt.title(\"Augmented image from ImageDataGenerator\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fcc89b",
   "metadata": {},
   "source": [
    "### Option 1 - Generate n * batch_size random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "aug_image_folder = os.path.join('datasets', 'face_dataset_train_aug_images')\n",
    "if not os.path.exists(aug_image_folder):\n",
    "    os.makedirs(aug_image_folder)  # create folder if doesn't exist\n",
    "\n",
    "# Note that the content of the folder is not deleted and files are added at every step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069988eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.save_to_dir = aug_image_folder\n",
    "train_generator.save_format = 'jpg'\n",
    "\n",
    "# If 'save_to_dir' is set, `next()` method\n",
    "# will generate `batch_size` images each time \n",
    "# and save them to 'save_to_dir' folder\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"Step {} of {}\".format(i+1, n))\n",
    "    train_generator.next()\n",
    "    print(\"\\tGenerate {} random images\".format(train_generator.batch_size))\n",
    "\n",
    "print(\"\\nTotal number images generated = {}\".format(n*train_generator.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf628163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the problem is to label data again - so you need to create two ImageDataGenerator objects\n",
    "\n",
    "# This example is good, and this dataset can be successfully used to train CNN, \n",
    "# but if you want to get more control, we can set number of images we want to get explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191a17f",
   "metadata": {},
   "source": [
    "### Option 2 - Generate n samples for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "aug_image_folder = os.path.join('datasets', 'face_dataset_train_aug_images')\n",
    "if not os.path.exists(aug_image_folder):\n",
    "    os.makedirs(aug_image_folder)  # create folder if doesn't exist\n",
    "\n",
    "# Note that the content of the folder is not deleted and files are added at every step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.7, 1),\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7eca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes: 'me' and 'not_me'\n",
    "image_folder_to_generate = os.path.join(image_folder, 'me')\n",
    "image_folder_to_save = os.path.join(aug_image_folder, 'me')\n",
    "if not os.path.exists(image_folder_to_save):\n",
    "    os.makedirs(image_folder_to_save)  # create folder if doesn't exist\n",
    "\n",
    "i = 0\n",
    "total = len(os.listdir(image_folder_to_generate))  # number of files in folder\n",
    "for filename in os.listdir(image_folder_to_generate):\n",
    "    print(\"Step {} of {}\".format(i+1, total))\n",
    "    # for each image in folder: read it\n",
    "    image_path = os.path.join(image_folder_to_generate, filename)\n",
    "    image = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(img_height, img_width, 3))\n",
    "    image = keras.preprocessing.image.img_to_array(\n",
    "        image)  # from image to array\n",
    "    # shape from (250, 250, 3) to (1, 250, 250, 3)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # create ImageDataGenerator object for it\n",
    "    current_image_gen = train_datagen.flow(image,\n",
    "                                           batch_size=1,\n",
    "                                           save_to_dir=image_folder_to_save,\n",
    "                                           save_prefix=filename,\n",
    "                                           save_format=\"jpg\")\n",
    "\n",
    "    # generate n samples\n",
    "    count = 0\n",
    "    for image in current_image_gen:  # accessing the object saves the image to disk\n",
    "        count += 1\n",
    "        if count == n:  # n images were generated\n",
    "            break\n",
    "    print('\\tGenerate {} samples for file {}'.format(n, filename))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\nTotal number images generated = {}\".format(n*total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5a931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "064b18af5d9d34f9d3726e2403c5118346c6eab14a59a5b3f0e0a0d981759afb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('mlp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
