{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5742b243",
   "metadata": {},
   "source": [
    "## Import libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if image is corrupted \n",
    "\n",
    "from pathlib import Path\n",
    "import imghdr\n",
    "\n",
    "data_dir = os.path.join('datasets', 'face_dataset_train_images', 'epi')\n",
    "image_extensions = [\".jpg\"] \n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    #if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        img_type\n",
    "        if img_type is None:\n",
    "           print(f\"{filepath} is not an image\")\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "           print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow imports\n",
    "# may differs from version to versions\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b9aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "\n",
    "image_folder = os.path.join('datasets', 'face_dataset_train_images')\n",
    "img_height, img_width = 250, 250  # size of images\n",
    "num_classes = 3  # me - not_me - epi\n",
    "\n",
    "# 'face_dataset_train_images' and 'face_dataset_test_images' folders follow next structure:\n",
    "# | - dataset_folder (face_dataset_train_images/face_dataset_test_images)\n",
    "#     | - class_1\n",
    "#         | - img1.jpg\n",
    "#         | - img2.jpg\n",
    "#         | - ...\n",
    "#     | - class_2\n",
    "#         | - img1.jpg\n",
    "#         | - img2.jpg\n",
    "#         | - ...\n",
    "#     | - ...\n",
    "\n",
    "# In my case\n",
    "# | - face_dataset_train_images\n",
    "#     | - me\n",
    "#         | - ...\n",
    "#     | - not_me\n",
    "#         | - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859cfc31",
   "metadata": {},
   "source": [
    "## Look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79149017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    image_folder,\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    label_mode='categorical',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41838ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1434591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get classname of the image\n",
    "def get_classname(class_names, mask):\n",
    "    '''\n",
    "    Returns an element of the array 'class_names' with the index\n",
    "    where the maximum value from the 'mask' array is located.\n",
    "    Used to get classname with categorical labels.\n",
    "\n",
    "    Parameters:\n",
    "        class_names (array-like): Target array\n",
    "        mask (array-like): Mask array, elements must be numbers\n",
    "    Returns:\n",
    "        One of the element from 'class_names'\n",
    "\n",
    "    >>> get_classname(['first', 'second'], [0, 1])\n",
    "    'second'\n",
    "    >>> get_classname(['first', 'second', third], [1, 0, 0])\n",
    "    'first'\n",
    "    '''\n",
    "\n",
    "    assert len(class_names) == len(\n",
    "        mask), \"The arrays must be of the same length\"\n",
    "\n",
    "    return class_names[np.array(mask).argmax(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae936905",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sqrt_img = 2  # images per row / col.\n",
    "# The square root of the total number of images shown\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in dataset.take(3):\n",
    "    for index in range(sqrt_img**2):\n",
    "        # grid 'sqrt_img' x 'sqrt_img'\n",
    "        plt.subplot(sqrt_img, sqrt_img, index + 1)\n",
    "        plt.imshow(images[index] / 255)\n",
    "        class_name = get_classname(class_names, labels[index])\n",
    "        plt.title(\"Class: {}\".format(class_name))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64def32f",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator based on ImageDataGenerator object\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.7, 1),\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    image_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see next augmented image\n",
    "image, label = train_generator.next()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image[0] / 255)  # first image from batch\n",
    "plt.title(\"Augmented image from ImageDataGenerator\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fcc89b",
   "metadata": {},
   "source": [
    "### Option 1 - Generate n * batch_size random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "aug_image_folder = os.path.join('datasets', 'face_dataset_train_aug_images')\n",
    "if not os.path.exists(aug_image_folder):\n",
    "    os.makedirs(aug_image_folder)  # create folder if doesn't exist\n",
    "\n",
    "# Note that the content of the folder is not deleted and files are added at every step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069988eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.save_to_dir = aug_image_folder\n",
    "train_generator.save_format = 'jpg'\n",
    "\n",
    "# If 'save_to_dir' is set, `next()` method\n",
    "# will generate `batch_size` images each time \n",
    "# and save them to 'save_to_dir' folder\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"Step {} of {}\".format(i+1, n))\n",
    "    train_generator.next()\n",
    "    print(\"\\tGenerate {} random images\".format(train_generator.batch_size))\n",
    "\n",
    "print(\"\\nTotal number images generated = {}\".format(n*train_generator.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf628163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the problem is to label data again - so you need to create two ImageDataGenerator objects\n",
    "\n",
    "# This example is good, and this dataset can be successfully used to train CNN, \n",
    "# but if you want to get more control, we can set number of images we want to get explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191a17f",
   "metadata": {},
   "source": [
    "### Option 2 - Generate n samples for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "aug_image_folder = os.path.join('datasets', 'face_dataset_train_aug_images')\n",
    "if not os.path.exists(aug_image_folder):\n",
    "    os.makedirs(aug_image_folder)  # create folder if doesn't exist\n",
    "\n",
    "# Note that the content of the folder is not deleted and files are added at every step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.7, 1),\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7eca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes: 'me' and 'not_me'\n",
    "#add epi\n",
    "image_folder_to_generate = os.path.join(image_folder, 'me')\n",
    "image_folder_to_save = os.path.join(aug_image_folder, 'me')\n",
    "if not os.path.exists(image_folder_to_save):\n",
    "    os.makedirs(image_folder_to_save)  # create folder if doesn't exist\n",
    "\n",
    "i = 0\n",
    "total = len(os.listdir(image_folder_to_generate))  # number of files in folder\n",
    "for filename in os.listdir(image_folder_to_generate):\n",
    "    print(\"Step {} of {}\".format(i+1, total))\n",
    "    # for each image in folder: read it\n",
    "    image_path = os.path.join(image_folder_to_generate, filename)\n",
    "    image = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(img_height, img_width, 3))\n",
    "    image = keras.preprocessing.image.img_to_array(\n",
    "        image)  # from image to array\n",
    "    # shape from (250, 250, 3) to (1, 250, 250, 3)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # create ImageDataGenerator object for it\n",
    "    current_image_gen = train_datagen.flow(image,\n",
    "                                           batch_size=1,\n",
    "                                           save_to_dir=image_folder_to_save,\n",
    "                                           save_prefix=filename,\n",
    "                                           save_format=\"jpg\")\n",
    "\n",
    "    # generate n samples\n",
    "    count = 0\n",
    "    for image in current_image_gen:  # accessing the object saves the image to disk\n",
    "        count += 1\n",
    "        if count == n:  # n images were generated\n",
    "            break\n",
    "    print('\\tGenerate {} samples for file {}'.format(n, filename))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\nTotal number images generated = {}\".format(n*total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epi \n",
    "image_folder_to_generate = os.path.join(image_folder, 'epi')\n",
    "image_folder_to_save = os.path.join(aug_image_folder, 'epi')\n",
    "if not os.path.exists(image_folder_to_save):\n",
    "    os.makedirs(image_folder_to_save)  # create folder if doesn't exist\n",
    "\n",
    "i = 0\n",
    "total = len(os.listdir(image_folder_to_generate))  # number of files in folder\n",
    "for filename in os.listdir(image_folder_to_generate):\n",
    "    print(\"Step {} of {}\".format(i+1, total))\n",
    "    # for each image in folder: read it\n",
    "    image_path = os.path.join(image_folder_to_generate, filename)\n",
    "    image = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(img_height, img_width, 3))\n",
    "    image = keras.preprocessing.image.img_to_array(\n",
    "        image)  # from image to array\n",
    "    # shape from (250, 250, 3) to (1, 250, 250, 3)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # create ImageDataGenerator object for it\n",
    "    current_image_gen = train_datagen.flow(image,\n",
    "                                           batch_size=1,\n",
    "                                           save_to_dir=image_folder_to_save,\n",
    "                                           save_prefix=filename,\n",
    "                                           save_format=\"jpg\")\n",
    "\n",
    "    # generate n samples\n",
    "    count = 0\n",
    "    for image in current_image_gen:  # accessing the object saves the image to disk\n",
    "        count += 1\n",
    "        if count == n:  # n images were generated\n",
    "            break\n",
    "    print('\\tGenerate {} samples for file {}'.format(n, filename))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\nTotal number images generated = {}\".format(n*total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5a931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "064b18af5d9d34f9d3726e2403c5118346c6eab14a59a5b3f0e0a0d981759afb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('mlp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
